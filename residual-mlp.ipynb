{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc8d3e-7169-4aa0-ae3e-396843951c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Subset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "class PandasDataset(Dataset):\n",
    "    def __init__(self, dataframe, cat_cols, target_col):\n",
    "        self.categorical = torch.tensor(dataframe[cat_cols].values, dtype=torch.int32)\n",
    "        #self.continuous = torch.tensor(dataframe[cont_cols].values, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(dataframe[target_col].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.categorical[index], self.targets[index]\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, embed):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(in_dim, out_dim) for in_dim, out_dim in embed]\n",
    "        )\n",
    "        \n",
    "        em_dim = sum(embed.embedding_dim for embed in self.embeddings)\n",
    "        self.linear1 = nn.Linear(em_dim, 128)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(128)\n",
    "        self.linear2 = nn.Linear(128, em_dim)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(em_dim)\n",
    "        self.linear3 = nn.Linear(em_dim, 32)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(32)\n",
    "        self.linear4 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = [embed(x[:, i]) for i, embed in enumerate(self.embeddings)]\n",
    "        embeddings = torch.cat(x, 1)\n",
    "        x = self.dropout(embeddings)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = torch.add(x, embeddings)\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.linear4(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "data = pd.read_csv('processed_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e65898-ff14-43a5-8aec-abab9f3b1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = data[data['CALL_TYPE'] == 'A']\n",
    "A_train, A_val = train_test_split(A, test_size=0.2, random_state=42)\n",
    "A_train = A_train.reset_index()\n",
    "A_val = A_val.reset_index()\n",
    "print(len(A_val))\n",
    "\n",
    "categorical_A = [\n",
    "    'ORIGIN_CALL',\n",
    "    'TAXI_ID',\n",
    "    'QTRHR',\n",
    "    'WK',\n",
    "    'WKYR',\n",
    "    'HOLIDAY'\n",
    "]\n",
    "train_A = PandasDataset(A_train, cat_cols=categorical_A, target_col='TRAVEL_TIME')\n",
    "val_A = PandasDataset(A_val, cat_cols=categorical_A, target_col='TRAVEL_TIME')\n",
    "A_train_dataloader = DataLoader(train_A, batch_size=512, shuffle=True, num_workers=16)\n",
    "A_val_dataloader = DataLoader(val_A, batch_size=512, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60db198-ddfc-4d1e-b87b-431c7ed04575",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim_A = [\n",
    "    (56481, 50),\n",
    "    (443, 50),\n",
    "    (96, 48),\n",
    "    (7, 4),\n",
    "    (52, 26),\n",
    "    (3, 2)\n",
    "]\n",
    "model_A = MyModel(embedding_dim_A).to(device)\n",
    "optimizer = optim.Adam(model_A.parameters(), lr=0.007, weight_decay=0.01)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69af52a-b4a9-4e52-912c-6ce61d484b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.eval()\n",
    "\n",
    "train_loss_list = []\n",
    "init_train_loss = 0.0\n",
    "with torch.no_grad(), tqdm(A_train_dataloader, desc=f\"Initial Training Loss\") as progress:\n",
    "    for inputs, targets in progress:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model_A(inputs)\n",
    "        loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "        \n",
    "        init_train_loss += loss.item()\n",
    "        progress.set_postfix({\"Train Loss\": loss.item()})\n",
    "\n",
    "init_train_loss /= len(A_train_dataloader)\n",
    "train_loss_list.append(init_train_loss)\n",
    "\n",
    "val_loss_list = []\n",
    "init_val_loss = 0.0\n",
    "with torch.no_grad(), tqdm(A_val_dataloader, desc=f\"Initial Validation Loss\") as progress:\n",
    "    for inputs, targets in progress:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model_A(inputs)\n",
    "        loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "        \n",
    "        init_val_loss += loss.item()\n",
    "        progress.set_postfix({\"Val Loss\": loss.item()})\n",
    "\n",
    "init_val_loss /= len(A_val_dataloader)\n",
    "val_loss_list.append(init_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace237fb-6c1c-4fae-9435-d7649192f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 8\n",
    "for epoch in range(max_epochs):\n",
    "    model_A.train()\n",
    "    train_loss = 0.0\n",
    "    with tqdm(A_train_dataloader, desc=f\"Epoch {epoch+1}/{max_epochs} - Training\") as progress:\n",
    "        for batch_idx, (inputs, targets) in enumerate(progress):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_A(inputs)\n",
    "            loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            train_loss += loss.item()\n",
    "            progress.set_postfix({\"Train Loss\": loss.item()})\n",
    "\n",
    "    train_loss /= len(A_train_dataloader)\n",
    "\n",
    "    model_A.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad(), tqdm(A_val_dataloader, desc=f\"Epoch {epoch+1}/{max_epochs} - Validation\") as progress:\n",
    "        for inputs, targets in progress:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model_A(inputs)\n",
    "            loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            progress.set_postfix({\"Val Loss\": loss.item()})\n",
    "\n",
    "    val_loss /= len(A_val_dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{max_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460b16d-428d-4ab9-9e03-de6d0961b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='Training Loss')\n",
    "plt.plot(x, val_loss_list, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.title('Loss Per Epoch - Model A')\n",
    "plt.legend()\n",
    "#plt.savefig('loss.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d9ad8-8eda-4399-b314-f6d07b9f5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), './A.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c375f80-075c-45f4-b9df-394c24ea3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = data[data['CALL_TYPE'] == 'B']\n",
    "B_train, B_val = train_test_split(B, test_size=0.2, random_state=42)\n",
    "B_train = B_train.reset_index()\n",
    "B_val = B_val.reset_index()\n",
    "print(len(B_val))\n",
    "\n",
    "categorical_B = [\n",
    "    'ORIGIN_STAND',\n",
    "    'TAXI_ID',\n",
    "    'QTRHR',\n",
    "    'WK',\n",
    "    'WKYR',\n",
    "    'HOLIDAY'\n",
    "]\n",
    "train_B = PandasDataset(B_train, cat_cols=categorical_B, target_col='TRAVEL_TIME')\n",
    "val_B = PandasDataset(B_val, cat_cols=categorical_B, target_col='TRAVEL_TIME')\n",
    "B_train_dataloader = DataLoader(train_B, batch_size=512, shuffle=True, num_workers=16)\n",
    "B_val_dataloader = DataLoader(val_B, batch_size=512, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e3d656-454b-4fd3-9620-25d55d24c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim_B = [\n",
    "    (64, 32),\n",
    "    (443, 50),\n",
    "    (96, 48),\n",
    "    (7, 4),\n",
    "    (52, 26),\n",
    "    (3, 2)\n",
    "]\n",
    "model_B = MyModel(embedding_dim_B).to(device)\n",
    "optimizer = optim.Adam(model_B.parameters(), lr=0.007, weight_decay=0.01)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be668f3b-f6a3-49b9-9610-8f5dddee3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.eval()\n",
    "\n",
    "train_loss_list = []\n",
    "init_train_loss = 0.0\n",
    "with torch.no_grad(), tqdm(B_train_dataloader, desc=f\"Initial Training Loss\") as progress:\n",
    "    for inputs, targets in progress:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model_B(inputs)\n",
    "        loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "        \n",
    "        init_train_loss += loss.item()\n",
    "        progress.set_postfix({\"Train Loss\": loss.item()})\n",
    "\n",
    "init_train_loss /= len(B_train_dataloader)\n",
    "train_loss_list.append(init_train_loss)\n",
    "\n",
    "val_loss_list = []\n",
    "init_val_loss = 0.0\n",
    "with torch.no_grad(), tqdm(B_val_dataloader, desc=f\"Initial Validation Loss\") as progress:\n",
    "    for inputs, targets in progress:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model_B(inputs)\n",
    "        loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "        \n",
    "        init_val_loss += loss.item()\n",
    "        progress.set_postfix({\"Val Loss\": loss.item()})\n",
    "\n",
    "init_val_loss /= len(B_val_dataloader)\n",
    "val_loss_list.append(init_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b14a9f-3c28-4b90-ba54-a722e24b63be",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 8\n",
    "for epoch in range(max_epochs):\n",
    "    model_B.train()\n",
    "    train_loss = 0.0\n",
    "    with tqdm(B_train_dataloader, desc=f\"Epoch {epoch+1}/{max_epochs} - Training\") as progress:\n",
    "        for batch_idx, (inputs, targets) in enumerate(progress):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_B(inputs)\n",
    "            loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            train_loss += loss.item()\n",
    "            progress.set_postfix({\"Train Loss\": loss.item()})\n",
    "\n",
    "    train_loss /= len(B_train_dataloader)\n",
    "\n",
    "    model_B.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad(), tqdm(B_val_dataloader, desc=f\"Epoch {epoch+1}/{max_epochs} - Validation\") as progress:\n",
    "        for inputs, targets in progress:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model_B(inputs)\n",
    "            loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            progress.set_postfix({\"Val Loss\": loss.item()})\n",
    "\n",
    "    val_loss /= len(B_val_dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{max_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02175747-0df5-488e-8b54-7509f95cb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='Training Loss')\n",
    "plt.plot(x, val_loss_list, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.title('Loss Per Epoch - Model B')\n",
    "plt.legend()\n",
    "#plt.savefig('loss.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a16405-c733-4c82-9b10-f086d22519f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), './B.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f2137-8a3d-49e3-8f83-7e978aab5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = data[data['CALL_TYPE'] == 'C']\n",
    "C_train, C_val = train_test_split(C, test_size=0.2, random_state=42)\n",
    "C_train = C_train.reset_index()\n",
    "C_val = C_val.reset_index()\n",
    "print(len(C_val))\n",
    "\n",
    "categorical_C = [\n",
    "    'TAXI_ID',\n",
    "    'QTRHR',\n",
    "    'WK',\n",
    "    'WKYR',\n",
    "    'HOLIDAY'\n",
    "]\n",
    "train_C = PandasDataset(C_train, cat_cols=categorical_C, target_col='TRAVEL_TIME')\n",
    "val_C = PandasDataset(C_val, cat_cols=categorical_C, target_col='TRAVEL_TIME')\n",
    "C_train_dataloader = DataLoader(train_C, batch_size=512, shuffle=True, num_workers=16)\n",
    "C_val_dataloader = DataLoader(val_C, batch_size=512, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12cf2d1-6f74-496f-85f8-c46260ef6f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim_C = [\n",
    "    (443, 50),\n",
    "    (96, 48),\n",
    "    (7, 4),\n",
    "    (52, 26),\n",
    "    (3, 2)\n",
    "]\n",
    "model_C = MyModel(embedding_dim_C).to(device)\n",
    "optimizer = optim.Adam(model_C.parameters(), lr=0.007, weight_decay=0.01)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72419b51-f991-40ed-9cee-eb195cc61921",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_C.eval()\n",
    "\n",
    "train_loss_list = []\n",
    "init_train_loss = 0.0\n",
    "with torch.no_grad(), tqdm(C_train_dataloader, desc=f\"Initial Training Loss\") as progress:\n",
    "    for inputs, targets in progress:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model_C(inputs)\n",
    "        loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "        \n",
    "        init_train_loss += loss.item()\n",
    "        progress.set_postfix({\"Train Loss\": loss.item()})\n",
    "\n",
    "init_train_loss /= len(C_train_dataloader)\n",
    "train_loss_list.append(init_train_loss)\n",
    "\n",
    "val_loss_list = []\n",
    "init_val_loss = 0.0\n",
    "with torch.no_grad(), tqdm(C_val_dataloader, desc=f\"Initial Validation Loss\") as progress:\n",
    "    for inputs, targets in progress:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model_C(inputs)\n",
    "        loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "        \n",
    "        init_val_loss += loss.item()\n",
    "        progress.set_postfix({\"Val Loss\": loss.item()})\n",
    "\n",
    "init_val_loss /= len(C_val_dataloader)\n",
    "val_loss_list.append(init_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df70590-d78a-48a2-a3af-45bc8f48d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 8\n",
    "for epoch in range(max_epochs):\n",
    "    model_C.train()\n",
    "    train_loss = 0.0\n",
    "    with tqdm(C_train_dataloader, desc=f\"Epoch {epoch+1}/{max_epochs} - Training\") as progress:\n",
    "        for batch_idx, (inputs, targets) in enumerate(progress):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_C(inputs)\n",
    "            loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            train_loss += loss.item()\n",
    "            progress.set_postfix({\"Train Loss\": loss.item()})\n",
    "\n",
    "    train_loss /= len(C_train_dataloader)\n",
    "\n",
    "    model_C.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad(), tqdm(C_val_dataloader, desc=f\"Epoch {epoch+1}/{max_epochs} - Validation\") as progress:\n",
    "        for inputs, targets in progress:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model_C(inputs)\n",
    "            loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            progress.set_postfix({\"Val Loss\": loss.item()})\n",
    "\n",
    "    val_loss /= len(C_val_dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{max_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1843d6d-20cf-48a7-99c2-087b2f27525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='Training Loss')\n",
    "plt.plot(x, val_loss_list, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.title('Loss Per Epoch - Model C')\n",
    "plt.legend()\n",
    "#plt.savefig('loss.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73233bc7-d456-4c4b-b1fb-e0051e6e8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalPandasDataset(Dataset):\n",
    "    def __init__(self, dataframe, cat_cols):\n",
    "        self.categorical = torch.tensor(dataframe[cat_cols].values, dtype=torch.int32)\n",
    "        self.ids = dataframe['TRIP_ID']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.categorical)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.ids[index], self.categorical[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3231d276-2d32-472b-a802-59d440357269",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('processed_test.csv')\n",
    "A_data_test = test[test['CALL_TYPE'] == 'A'].reset_index()\n",
    "B_data_test = test[test['CALL_TYPE'] == 'B'].reset_index()\n",
    "C_data_test = test[test['CALL_TYPE'] == 'C'].reset_index()\n",
    "A_test = EvalPandasDataset(A_data_test, categorical_A)\n",
    "B_test = EvalPandasDataset(B_data_test, categorical_B)\n",
    "C_test = EvalPandasDataset(C_data_test, categorical_C)\n",
    "A_test_dataloader = DataLoader(A_test, batch_size=64, shuffle=False, num_workers=8)\n",
    "B_test_dataloader = DataLoader(B_test, batch_size=64, shuffle=False, num_workers=8)\n",
    "C_test_dataloader = DataLoader(C_test, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deed1da-fdda-4c4e-a0ab-1b73a227cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.eval()\n",
    "create_array = True\n",
    "with torch.no_grad(), tqdm(A_test_dataloader, desc=f\"A\") as progress:\n",
    "    for id, inputs in progress:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model_A(inputs)\n",
    "\n",
    "        if create_array:\n",
    "            ids = id\n",
    "            score = outputs\n",
    "            create_array = False\n",
    "        else:\n",
    "            ids = ids + id\n",
    "            score = torch.cat((score, outputs))\n",
    "            \n",
    "model_B.eval()\n",
    "with torch.no_grad(), tqdm(B_test_dataloader, desc=f\"B\") as progress:\n",
    "    for id, inputs in progress:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model_B(inputs)\n",
    "\n",
    "        ids = ids + id\n",
    "        score = torch.cat((score, outputs))\n",
    "\n",
    "model_C.eval()\n",
    "with torch.no_grad(), tqdm(C_test_dataloader, desc=f\"C\") as progress:\n",
    "    for id, inputs in progress:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model_C(inputs)\n",
    "\n",
    "        ids = ids + id\n",
    "        score = torch.cat((score, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7f801-f0fd-4bd9-857c-7931d8fd67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'TRIP_ID': ids, 'TRAVEL_TIME': score.cpu()})\n",
    "def extract_id(value):\n",
    "    return int(value[1:])\n",
    "df_sorted = df.iloc[df['TRIP_ID'].map(extract_id).argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292d451-7634-4d9e-9ef7-61c3d7a6430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad362e-f1b9-467a-b804-314e6bfc0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d467d5-b286-4eae-ad19-a6ecde13dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model_A.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394739b-4e12-4ff9-9151-8af7e56ca36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model_B.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f72a90-366a-4ad9-b96c-e0042780eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model_C.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93594df-e55d-4b37-bf16-d120a52ddf54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
